# FeelSync: Sistema de RecomendaciÃ³n Basado en Emociones

## DescripciÃ³n
FeelSync es un sistema de recomendaciÃ³n hÃ­brido que integra anÃ¡lisis emocional, procesamiento del lenguaje natural (NLP) y aprendizaje profundo para ofrecer recomendaciones personalizadas de contenido en funciÃ³n del estado emocional del usuario.

Este proyecto es el Trabajo de Fin de MÃ¡ster desarrollado por Helen Carolina Roda Garcia y Lina Marcela Angel Cetina como parte de su formaciÃ³n en la Universidad Internacional de La Rioja (UNIR).

## CaracterÃ­sticas Clave
- ClasificaciÃ³n de emociones con BERT.
- RecomendaciÃ³n hÃ­brida con filtrado colaborativo y basado en contenido.
- ImplementaciÃ³n de un prototipo interactivo en Streamlit.
- IntegraciÃ³n de datasets de Netflix, MovieLens y Last.FM.

## Estructura del Proyecto
```
FeelSync/
â”œâ”€â”€ data/               # Almacenamiento de datasets
â”‚   â”œâ”€â”€ raw/            # Datasets originales sin procesar
â”‚   â”œâ”€â”€ processed/      # Datasets limpios y transformados
â”‚   â”œâ”€â”€ predictions/    # Datos con predicciones de modelos
â”‚
â”œâ”€â”€ notebooks/          # Jupyter notebooks para exploraciÃ³n y modelado
â”‚   â”œâ”€â”€ 01-data-exploration.ipynb
â”‚   â”œâ”€â”€ 02-feature-engineering.ipynb
â”‚   â”œâ”€â”€ 03-model-training.ipynb
â”‚   â”œâ”€â”€ 04-evaluation.ipynb
â”‚
â”œâ”€â”€ src/                # CÃ³digo fuente modular
â”‚   â”œâ”€â”€ data/           # Scripts de carga y procesamiento de datos
â”‚   â”œâ”€â”€ features/       # IngenierÃ­a de caracterÃ­sticas
â”‚   â”œâ”€â”€ models/         # Entrenamiento y evaluaciÃ³n de modelos
â”‚   â”œâ”€â”€ visualizations/ # GeneraciÃ³n de visualizaciones
â”‚
â”œâ”€â”€ tests/              # Pruebas unitarias
â”œâ”€â”€ reports/            # Reportes y visualizaciones
â”œâ”€â”€ docs/               # DocumentaciÃ³n del proyecto
â”œâ”€â”€ app/                # ImplementaciÃ³n en Streamlit
â”‚   â”œâ”€â”€ feelsync.py
â”‚   â”œâ”€â”€ assets/
â”‚
â”œâ”€â”€ demo/               # Video demostrativo
â”‚   â”œâ”€â”€ feelsync_demo_interfaz.mp4
â”‚
â”œâ”€â”€ requirements.txt    # Dependencias del proyecto
â”œâ”€â”€ .gitignore          # Archivos a ignorar en Git
â”œâ”€â”€ LICENSE             # Licencia del proyecto
â””â”€â”€ architecture.md     # ExplicaciÃ³n de la arquitectura del sistema
```

## InstalaciÃ³n y Uso

### 1. Clonar el repositorio
```bash
git clone https://github.com/mare2868/FeelSync.git
cd FeelSync
```

### 2. Crear entorno virtual e instalar dependencias
```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### 3. Ejecutar la aplicaciÃ³n en Streamlit
```bash
streamlit run app/feelsync.py
```

## Video de DemostraciÃ³n ğŸ¬
Puedes ver una demo del funcionamiento de la interfaz en la carpeta [`demo/`](./demo).

ğŸ“ Archivo: `feelsync_demo_interfaz.mp4`  
ğŸ§­ Muestra cÃ³mo el usuario selecciona gÃ©nero y emociÃ³n para recibir recomendaciones personalizadas.

## Modelos Utilizados
- BERT: Para la clasificaciÃ³n de emociones.
- Red Neuronal Profunda: Para la generaciÃ³n de recomendaciones.
- Filtrado Colaborativo y Basado en Contenido: Para optimizar la personalizaciÃ³n.

## ContribuciÃ³n
Si deseas mejorar FeelSync, puedes hacer un fork del repositorio y enviar un pull request con tus cambios.

## Licencia
Este proyecto estÃ¡ bajo la licencia MIT.

---

Hecho con â¤ï¸ por Helen Carolina Roda Garcia y Lina Marcela Angel Cetina